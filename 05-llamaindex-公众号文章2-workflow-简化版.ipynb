{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 基础工作流构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，世界！\n"
     ]
    }
   ],
   "source": [
    "# 导入基础工作流组件\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "\n",
    "# 定义一个简单的工作流\n",
    "class MyWorkflow(Workflow):\n",
    "    @step\n",
    "    async def my_step(self, ev: StartEvent) -> StopEvent:\n",
    "        # 在这里执行任务\n",
    "        return StopEvent(result=\"你好，世界！\")\n",
    "\n",
    "# 创建并运行工作流\n",
    "w = MyWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run()\n",
    "print(result)  # 输出: 你好，世界！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个最小工作流仅包含一个步骤，接收StartEvent并返回StopEvent。在Jupyter环境中，可以直接使用await；在普通Python脚本中，需要使用asyncio进行包装;在jupyter环境中使用asyncio包装可能会报错，这个时候需要导入 nest_asyncio 解决问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，世界！\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    w = MyWorkflow(timeout=10, verbose=False)\n",
    "    result = await w.run()\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 自定义事件与多步骤工作流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始工作流。\n",
      "第一步完成。\n",
      "第二步完成。\n",
      "工作流完成。\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    ")\n",
    "\n",
    "# 定义自定义事件\n",
    "class FirstEvent(Event):\n",
    "    first_output: str\n",
    "\n",
    "class SecondEvent(Event):\n",
    "    second_output: str\n",
    "\n",
    "# 定义三步工作流\n",
    "class MyWorkflow(Workflow):\n",
    "    @step\n",
    "    async def step_one(self, ev: StartEvent) -> FirstEvent:\n",
    "        print(ev.first_input)\n",
    "        return FirstEvent(first_output=\"第一步完成。\")\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ev: FirstEvent) -> SecondEvent:\n",
    "        print(ev.first_output)\n",
    "        return SecondEvent(second_output=\"第二步完成。\")\n",
    "\n",
    "    @step\n",
    "    async def step_three(self, ev: SecondEvent) -> StopEvent:\n",
    "        print(ev.second_output)\n",
    "        return StopEvent(result=\"工作流完成。\")\n",
    "\n",
    "# 运行工作流\n",
    "w = MyWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run(first_input=\"开始工作流。\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个示例展示了如何通过自定义事件连接多个步骤，形成一个连贯的工作流程。每个步骤接收特定类型的事件，并返回另一个类型的事件，驱动工作流向前推进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 添加分支和循环逻辑\n",
    "\n",
    "实际应用中的工作流通常需要处理条件分支和循环逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发生了好事\n",
      "第一步完成。\n",
      "第二步完成。\n",
      "工作流完成。\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    ")\n",
    "\n",
    "# 定义事件\n",
    "class FirstEvent(Event):\n",
    "    first_output: str\n",
    "\n",
    "class SecondEvent(Event):\n",
    "    second_output: str\n",
    "\n",
    "class LoopEvent(Event):\n",
    "    loop_output: str\n",
    "\n",
    "# 包含循环的工作流\n",
    "class MyWorkflow(Workflow):\n",
    "    @step \n",
    "    async def step_one(self, ev: StartEvent | LoopEvent) -> FirstEvent | LoopEvent:\n",
    "        if random.randint(0, 1) == 0:\n",
    "            print(\"发生了不好的事情\")\n",
    "            return LoopEvent(loop_output=\"返回第一步。\")\n",
    "        else:\n",
    "            print(\"发生了好事\")\n",
    "            return FirstEvent(first_output=\"第一步完成。\")\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ev: FirstEvent) -> SecondEvent:\n",
    "        print(ev.first_output)\n",
    "        return SecondEvent(second_output=\"第二步完成。\")\n",
    "\n",
    "    @step\n",
    "    async def step_three(self, ev: SecondEvent) -> StopEvent:\n",
    "        print(ev.second_output)\n",
    "        return StopEvent(result=\"工作流完成。\")\n",
    "\n",
    "# 运行工作流\n",
    "w = MyWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，step_one可以接收两种类型的事件：StartEvent或LoopEvent，并且可以返回两种类型的事件：FirstEvent或LoopEvent。当返回LoopEvent时，控制流会回到step_one，形成循环。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 工作流中的分支"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进入分支A\n",
      "分支A\n",
      "分支A\n",
      "分支A完成。\n"
     ]
    }
   ],
   "source": [
    "import random   \n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    ")\n",
    "\n",
    "# 定义分支事件\n",
    "class BranchA1Event(Event):\n",
    "    payload: str\n",
    "\n",
    "class BranchA2Event(Event):\n",
    "    payload: str\n",
    "\n",
    "class BranchB1Event(Event):\n",
    "    payload: str\n",
    "\n",
    "class BranchB2Event(Event):\n",
    "    payload: str\n",
    "\n",
    "# 包含分支的工作流\n",
    "class BranchWorkflow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ev: StartEvent) -> BranchA1Event | BranchB1Event:\n",
    "        if random.randint(0, 1) == 0:\n",
    "            print(\"进入分支A\")\n",
    "            return BranchA1Event(payload=\"分支A\")\n",
    "        else:\n",
    "            print(\"进入分支B\")\n",
    "            return BranchB1Event(payload=\"分支B\")\n",
    "\n",
    "    @step\n",
    "    async def step_a1(self, ev: BranchA1Event) -> BranchA2Event:\n",
    "        print(ev.payload)\n",
    "        return BranchA2Event(payload=ev.payload)\n",
    "\n",
    "    @step\n",
    "    async def step_b1(self, ev: BranchB1Event) -> BranchB2Event:\n",
    "        print(ev.payload)\n",
    "        return BranchB2Event(payload=ev.payload)\n",
    "\n",
    "    @step\n",
    "    async def step_a2(self, ev: BranchA2Event) -> StopEvent:\n",
    "        print(ev.payload)\n",
    "        return StopEvent(result=\"分支A完成。\")\n",
    "\n",
    "    @step\n",
    "    async def step_b2(self, ev: BranchB2Event) -> StopEvent:\n",
    "        print(ev.payload)\n",
    "        return StopEvent(result=\"分支B完成。\")\n",
    "\n",
    "# 运行工作流\n",
    "w = BranchWorkflow(timeout=10, verbose=False)\n",
    "result = await w.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，工作流根据随机选择进入不同的执行分支。这种能力在需要条件处理的场景中非常有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 状态管理\n",
    "在工作流中，经常需要在不同步骤之间共享数据。LlamaIndex提供了Context对象来解决这个问题：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要加载数据\n",
      "数据是 [1, 2, 3]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    ")\n",
    "\n",
    "# 定义事件\n",
    "class SetupEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class StepTwoEvent(Event):\n",
    "    query: str\n",
    "\n",
    "# 有状态的工作流\n",
    "class StatefulFlow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> SetupEvent | StepTwoEvent:\n",
    "        # 获取上下文中的数据\n",
    "        db = await ctx.get(\"some_database\", default=None)\n",
    "        if db is None:\n",
    "            print(\"需要加载数据\")\n",
    "            return SetupEvent(query=ev.query)\n",
    "        return StepTwoEvent(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def setup(self, ctx: Context, ev: SetupEvent) -> StartEvent:\n",
    "        # 在上下文中设置数据\n",
    "        await ctx.set(\"some_database\", [1, 2, 3])\n",
    "        return StartEvent(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StopEvent:\n",
    "        # 使用上下文中的数据\n",
    "        print(\"数据是\", await ctx.get(\"some_database\"))\n",
    "        return StopEvent(result=await ctx.get(\"some_database\"))\n",
    "\n",
    "# 运行工作流\n",
    "w = StatefulFlow(timeout=10, verbose=False)\n",
    "result = await w.run(query=\"示例查询\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 并发执行\n",
    "LlamaIndex工作流支持并发执行多个任务，极大提高处理效率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step start\n",
      "Step start produced no event\n",
      "Running step step_two\n",
      "执行慢查询: 查询1\n",
      "Running step step_two\n",
      "执行慢查询: 查询2\n",
      "Running step step_two\n",
      "执行慢查询: 查询3\n",
      "Step step_two produced event StopEvent\n",
      "Step step_two produced event StopEvent\n",
      "工作流完成，结果: 查询1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import asyncio\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent, StopEvent, Workflow, step, Event, Context\n",
    ")\n",
    "\n",
    "# 定义事件\n",
    "class StepTwoEvent(Event):\n",
    "    query: str\n",
    "\n",
    "# 并行工作流\n",
    "class ParallelFlow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> StepTwoEvent:\n",
    "        # 发送多个事件并行执行\n",
    "        ctx.send_event(StepTwoEvent(query=\"查询1\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"查询2\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"查询3\"))\n",
    "\n",
    "    @step(num_workers=4)  # 设置最大并发工作线程数\n",
    "    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StopEvent:\n",
    "        # 模拟慢查询\n",
    "        print(f\"执行慢查询: {ev.query}\")\n",
    "        await asyncio.sleep(random.randint(1, 5))\n",
    "        return StopEvent(result=ev.query)\n",
    "\n",
    "# 运行工作流\n",
    "workflow = ParallelFlow(timeout=10, verbose=True)\n",
    "result = await workflow.run()\n",
    "print(f\"工作流完成，结果: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，step_two使用了@step(num_workers=4)装饰器，允许最多同时运行4个该步骤的实例，处理不同的事件。这大大提高了处理多个查询的效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. 事件收集\n",
    "在并行执行的场景中，我们可能希望等待所有并行任务完成后再继续。LlamaIndex提供了事件收集机制："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step start\n",
      "Step start produced no event\n",
      "Running step step_two\n",
      "执行慢查询: 查询1\n",
      "Running step step_two\n",
      "执行慢查询: 查询2\n",
      "Running step step_two\n",
      "执行慢查询: 查询3\n",
      "Step step_two produced event StepThreeEvent\n",
      "Running step step_three\n",
      "Step step_three produced no event\n",
      "Step step_two produced event StepThreeEvent\n",
      "Step step_two produced event StepThreeEvent\n",
      "Running step step_three\n",
      "Step step_three produced no event\n",
      "Running step step_three\n",
      "所有查询结果: [StepThreeEvent(result='查询1'), StepThreeEvent(result='查询2'), StepThreeEvent(result='查询3')]\n",
      "Step step_three produced event StopEvent\n",
      "工作流最终结果: 所有查询已完成\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import asyncio\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent, StopEvent, Workflow, step, Event, Context\n",
    ")\n",
    "\n",
    "# 定义事件\n",
    "class StepTwoEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class StepThreeEvent(Event):\n",
    "    result: str\n",
    "\n",
    "# 并发工作流\n",
    "class ConcurrentFlow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> StepTwoEvent:\n",
    "        # 发送多个事件并行执行\n",
    "        ctx.send_event(StepTwoEvent(query=\"查询1\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"查询2\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"查询3\"))\n",
    "\n",
    "    @step(num_workers=4)\n",
    "    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StepThreeEvent:\n",
    "        # 模拟慢查询\n",
    "        print(f\"执行慢查询: {ev.query}\")\n",
    "        await asyncio.sleep(random.randint(1, 5))\n",
    "        return StepThreeEvent(result=ev.query)\n",
    "        \n",
    "    @step\n",
    "    async def step_three(self, ctx: Context, ev: StepThreeEvent) -> StopEvent:\n",
    "        # 等待收集3个事件\n",
    "        result = ctx.collect_events(ev, [StepThreeEvent] * 3)\n",
    "        if result is None:\n",
    "            return None  # 返回None表示继续等待更多事件\n",
    "        \n",
    "        # 处理所有查询结果\n",
    "        print(\"所有查询结果:\", result)\n",
    "        return StopEvent(result=\"所有查询已完成\")\n",
    "\n",
    "# 运行工作流\n",
    "workflow = ConcurrentFlow(timeout=10, verbose=True)\n",
    "result = await workflow.run()\n",
    "print(f\"工作流最终结果: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 可视化工作流\n",
    "LlamaIndex提供了工具帮助可视化工作流结构，便于理解和调试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class '__main__.FirstEvent'>\n",
      "<class '__main__.LoopEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.SecondEvent'>\n",
      "workflow_visualization.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "# 可视化工作流\n",
    "draw_all_possible_flows(MyWorkflow, filename=\"workflow_visualization.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 实际应用示例\n",
    "\n",
    "数据处理工作流"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class DataProcessingWorkflow(Workflow):\n",
    "    @step\n",
    "    async def fetch_data(self, ctx: Context, ev: StartEvent) -> DataFetchedEvent:\n",
    "        # 从API获取数据\n",
    "        data = await fetch_data_from_api(ev.api_endpoint)\n",
    "        await ctx.set(\"raw_data\", data)\n",
    "        return DataFetchedEvent(status=\"数据获取成功\")\n",
    "    \n",
    "    @step\n",
    "    async def process_data(self, ctx: Context, ev: DataFetchedEvent) -> DataProcessedEvent:\n",
    "        # 处理原始数据\n",
    "        raw_data = await ctx.get(\"raw_data\")\n",
    "        processed_data = process_raw_data(raw_data)\n",
    "        await ctx.set(\"processed_data\", processed_data)\n",
    "        return DataProcessedEvent(status=\"数据处理成功\")\n",
    "    \n",
    "    @step\n",
    "    async def analyze_data(self, ctx: Context, ev: DataProcessedEvent) -> AnalysisCompleteEvent:\n",
    "        # 分析处理后的数据\n",
    "        processed_data = await ctx.get(\"processed_data\")\n",
    "        analysis_result = analyze_data(processed_data)\n",
    "        await ctx.set(\"analysis_result\", analysis_result)\n",
    "        return AnalysisCompleteEvent(status=\"数据分析完成\")\n",
    "    \n",
    "    @step\n",
    "    async def generate_report(self, ctx: Context, ev: AnalysisCompleteEvent) -> StopEvent:\n",
    "        # 生成分析报告\n",
    "        analysis_result = await ctx.get(\"analysis_result\")\n",
    "        report = generate_report_from_analysis(analysis_result)\n",
    "        return StopEvent(result=report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据处理和分析工作流\n",
    "这个工作流模拟了一个数据获取、处理、分析和生成报告的完整流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step fetch_data\n",
      "从https://api.example.com/sales_data获取数据...\n",
      "Step fetch_data produced event DataFetchedEvent\n",
      "Running step process_data\n",
      "处理原始数据...\n",
      "Step process_data produced event DataProcessedEvent\n",
      "Running step analyze_data\n",
      "分析处理后的数据...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 38144 (\\N{CJK UNIFIED IDEOGRAPH-9500}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 21806 (\\N{CJK UNIFIED IDEOGRAPH-552E}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 39069 (\\N{CJK UNIFIED IDEOGRAPH-989D}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 36235 (\\N{CJK UNIFIED IDEOGRAPH-8D8B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 21183 (\\N{CJK UNIFIED IDEOGRAPH-52BF}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 26512 (\\N{CJK UNIFIED IDEOGRAPH-6790}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 26085 (\\N{CJK UNIFIED IDEOGRAPH-65E5}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 26399 (\\N{CJK UNIFIED IDEOGRAPH-671F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 27599 (\\N{CJK UNIFIED IDEOGRAPH-6BCF}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 31227 (\\N{CJK UNIFIED IDEOGRAPH-79FB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 21160 (\\N{CJK UNIFIED IDEOGRAPH-52A8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 24179 (\\N{CJK UNIFIED IDEOGRAPH-5E73}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n",
      "C:\\Users\\Cheng\\AppData\\Local\\Temp\\ipykernel_19772\\1127546308.py:74: UserWarning: Glyph 22343 (\\N{CJK UNIFIED IDEOGRAPH-5747}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(buffer, format='png')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step analyze_data produced event AnalysisCompleteEvent\n",
      "Running step generate_report\n",
      "生成分析报告...\n",
      "Step generate_report produced event StopEvent\n",
      "\n",
      "工作流执行完成!\n",
      "报告已保存到 sales_analysis_report.md\n",
      "\n",
      "报告摘要:\n",
      "\n",
      "    # 销售数据分析报告\n",
      "    \n",
      "    ## 摘要\n",
      "    - 总销售额: 16852\n",
      "    - 日均销售额: 561.73\n",
      "    - 销售峰值日: 2023-01-18 (销售额: 949)\n",
      "    - 平均转化率: 24.98%\n",
      "    - 销售趋势: increasing\n",
      "    \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent, StopEvent, Workflow, step, Event, Context\n",
    ")\n",
    "\n",
    "# 定义事件\n",
    "class DataFetchedEvent(Event):\n",
    "    status: str\n",
    "\n",
    "class DataProcessedEvent(Event):\n",
    "    status: str\n",
    "\n",
    "class AnalysisCompleteEvent(Event):\n",
    "    status: str\n",
    "\n",
    "# 模拟数据获取函数\n",
    "async def fetch_data_from_api(api_endpoint: str):\n",
    "    print(f\"从{api_endpoint}获取数据...\")\n",
    "    await asyncio.sleep(1)  # 模拟API调用延迟\n",
    "    \n",
    "    # 模拟生成数据\n",
    "    data = {\n",
    "        'date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n",
    "        'sales': [random.randint(100, 1000) for _ in range(30)],\n",
    "        'visitors': [random.randint(500, 5000) for _ in range(30)]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# 数据处理函数\n",
    "def process_raw_data(raw_data):\n",
    "    print(\"处理原始数据...\")\n",
    "    \n",
    "    # 计算移动平均\n",
    "    processed_data = raw_data.copy()\n",
    "    processed_data['sales_ma7'] = processed_data['sales'].rolling(window=7).mean()\n",
    "    processed_data['visitors_ma7'] = processed_data['visitors'].rolling(window=7).mean()\n",
    "    \n",
    "    # 计算转化率\n",
    "    processed_data['conversion_rate'] = processed_data['sales'] / processed_data['visitors'] * 100\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# 数据分析函数\n",
    "def analyze_data(processed_data):\n",
    "    print(\"分析处理后的数据...\")\n",
    "    \n",
    "    # 基本统计分析\n",
    "    analysis = {\n",
    "        'total_sales': processed_data['sales'].sum(),\n",
    "        'avg_daily_sales': processed_data['sales'].mean(),\n",
    "        'peak_sales_day': processed_data.loc[processed_data['sales'].idxmax(), 'date'].strftime('%Y-%m-%d'),\n",
    "        'peak_sales': processed_data['sales'].max(),\n",
    "        'avg_conversion_rate': processed_data['conversion_rate'].mean(),\n",
    "        'sales_trend': 'increasing' if processed_data['sales'].iloc[-1] > processed_data['sales'].iloc[0] else 'decreasing',\n",
    "    }\n",
    "    \n",
    "    # 创建销售图表\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(processed_data['date'], processed_data['sales'], 'b-', label='每日销售')\n",
    "    plt.plot(processed_data['date'], processed_data['sales_ma7'], 'r-', label='7日移动平均')\n",
    "    plt.title('销售趋势分析')\n",
    "    plt.xlabel('日期')\n",
    "    plt.ylabel('销售额')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 将图表转换为base64编码的图片\n",
    "    buffer = BytesIO()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    image_png = buffer.getvalue()\n",
    "    buffer.close()\n",
    "    plt.close()\n",
    "    \n",
    "    graph = base64.b64encode(image_png).decode('utf-8')\n",
    "    analysis['sales_graph'] = graph\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# 生成报告函数\n",
    "def generate_report_from_analysis(analysis):\n",
    "    print(\"生成分析报告...\")\n",
    "    \n",
    "    report = f\"\"\"\n",
    "    # 销售数据分析报告\n",
    "    \n",
    "    ## 摘要\n",
    "    - 总销售额: {analysis['total_sales']}\n",
    "    - 日均销售额: {round(analysis['avg_daily_sales'], 2)}\n",
    "    - 销售峰值日: {analysis['peak_sales_day']} (销售额: {analysis['peak_sales']})\n",
    "    - 平均转化率: {round(analysis['avg_conversion_rate'], 2)}%\n",
    "    - 销售趋势: {analysis['sales_trend']}\n",
    "    \n",
    "    ## 销售趋势图表\n",
    "    ![销售趋势](data:image/png;base64,{analysis['sales_graph']})\n",
    "    \n",
    "    ## 建议\n",
    "    - {'增加营销投入以维持上升趋势' if analysis['sales_trend'] == 'increasing' else '调整销售策略以扭转下降趋势'}\n",
    "    - 进一步分析峰值销售日的因素，重复成功经验\n",
    "    - {'转化率表现良好，继续保持' if analysis['avg_conversion_rate'] > 15 else '需要改进网站体验提高转化率'}\n",
    "    \n",
    "    *报告生成日期: {pd.Timestamp.now().strftime('%Y-%m-%d')}*\n",
    "    \"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# 数据处理工作流\n",
    "class DataProcessingWorkflow(Workflow):\n",
    "    @step\n",
    "    async def fetch_data(self, ctx: Context, ev: StartEvent) -> DataFetchedEvent:\n",
    "        # 从API获取数据\n",
    "        data = await fetch_data_from_api(ev.api_endpoint)\n",
    "        await ctx.set(\"raw_data\", data)\n",
    "        return DataFetchedEvent(status=\"数据获取成功\")\n",
    "    \n",
    "    @step\n",
    "    async def process_data(self, ctx: Context, ev: DataFetchedEvent) -> DataProcessedEvent:\n",
    "        # 处理原始数据\n",
    "        raw_data = await ctx.get(\"raw_data\")\n",
    "        processed_data = process_raw_data(raw_data)\n",
    "        await ctx.set(\"processed_data\", processed_data)\n",
    "        return DataProcessedEvent(status=\"数据处理成功\")\n",
    "    \n",
    "    @step\n",
    "    async def analyze_data(self, ctx: Context, ev: DataProcessedEvent) -> AnalysisCompleteEvent:\n",
    "        # 分析处理后的数据\n",
    "        processed_data = await ctx.get(\"processed_data\")\n",
    "        analysis_result = analyze_data(processed_data)\n",
    "        await ctx.set(\"analysis_result\", analysis_result)\n",
    "        return AnalysisCompleteEvent(status=\"数据分析完成\")\n",
    "    \n",
    "    @step\n",
    "    async def generate_report(self, ctx: Context, ev: AnalysisCompleteEvent) -> StopEvent:\n",
    "        # 生成分析报告\n",
    "        analysis_result = await ctx.get(\"analysis_result\")\n",
    "        report = generate_report_from_analysis(analysis_result)\n",
    "        return StopEvent(result=report)\n",
    "\n",
    "# 运行工作流\n",
    "async def run_data_workflow():\n",
    "    workflow = DataProcessingWorkflow(timeout=30, verbose=True)\n",
    "    result = await workflow.run(api_endpoint=\"https://api.example.com/sales_data\")\n",
    "    \n",
    "    # 将报告保存到文件\n",
    "    with open(\"sales_analysis_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(result)\n",
    "    \n",
    "    print(\"\\n工作流执行完成!\")\n",
    "    print(f\"报告已保存到 sales_analysis_report.md\")\n",
    "    \n",
    "    # 打印报告摘要\n",
    "    print(\"\\n报告摘要:\")\n",
    "    print(\"\\n\".join(result.split(\"\\n\")[:10]) + \"\\n...\")\n",
    "\n",
    "# 主函数\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run_data_workflow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个工作流会:\n",
    "从模拟API获取销售数据\n",
    "处理数据(计算移动平均和转化率)\n",
    "分析数据并生成图表\n",
    "创建一份包含洞察和可视化图表的Markdown报告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. AI辅助内容生成工作流\n",
    "\n",
    "这个工作流展示了如何使用LlamaIndex工作流结合OpenAI创建一个自动化内容生成系统:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ContentGenerationWorkflow(Workflow):\n",
    "    @step\n",
    "    async def research_topic(self, ctx: Context, ev: StartEvent) -> ResearchCompleteEvent:\n",
    "        # 研究主题\n",
    "        research_results = await research_topic_online(ev.topic)\n",
    "        await ctx.set(\"research_results\", research_results)\n",
    "        return ResearchCompleteEvent(status=\"研究完成\")\n",
    "    \n",
    "    @step\n",
    "    async def generate_outline(self, ctx: Context, ev: ResearchCompleteEvent) -> OutlineCompleteEvent:\n",
    "        # 生成内容大纲\n",
    "        research_results = await ctx.get(\"research_results\")\n",
    "        outline = await generate_outline_with_llm(research_results, ev.requirements)\n",
    "        await ctx.set(\"outline\", outline)\n",
    "        return OutlineCompleteEvent(status=\"大纲生成完成\")\n",
    "    \n",
    "    @step\n",
    "    async def write_content(self, ctx: Context, ev: OutlineCompleteEvent) -> WritingCompleteEvent:\n",
    "        # 根据大纲撰写内容\n",
    "        outline = await ctx.get(\"outline\")\n",
    "        research_results = await ctx.get(\"research_results\")\n",
    "        \n",
    "        # 并行撰写各个部分\n",
    "        sections = outline.split_into_sections()\n",
    "        for section in sections:\n",
    "            ctx.send_event(WriteSectionEvent(section=section))\n",
    "        \n",
    "        return WritingCompleteEvent(status=\"内容撰写启动\")\n",
    "    \n",
    "    @step(num_workers=5)\n",
    "    async def write_section(self, ctx: Context, ev: WriteSectionEvent) -> SectionCompleteEvent:\n",
    "        # 撰写单个部分\n",
    "        research_results = await ctx.get(\"research_results\")\n",
    "        section_content = await write_section_with_llm(ev.section, research_results)\n",
    "        \n",
    "        # 存储部分内容\n",
    "        sections = await ctx.get(\"completed_sections\", default=[])\n",
    "        sections.append({\"section\": ev.section, \"content\": section_content})\n",
    "        await ctx.set(\"completed_sections\", sections)\n",
    "        \n",
    "        return SectionCompleteEvent(section=ev.section)\n",
    "    \n",
    "    @step\n",
    "    async def compile_content(self, ctx: Context, ev: SectionCompleteEvent) -> StopEvent:\n",
    "        # 收集所有部分并编译完整内容\n",
    "        outline = await ctx.get(\"outline\")\n",
    "        sections_needed = len(outline.split_into_sections())\n",
    "        \n",
    "        # 收集所有部分\n",
    "        result = ctx.collect_events(ev, [SectionCompleteEvent] * sections_needed)\n",
    "        if result is None:\n",
    "            return None\n",
    "        \n",
    "        # 所有部分都已完成，编译最终内容\n",
    "        completed_sections = await ctx.get(\"completed_sections\")\n",
    "        final_content = compile_sections_into_document(completed_sections)\n",
    "        \n",
    "        return StopEvent(result=final_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行工作流时遇到错误: The following events are consumed but never produced: WriteSectionEvent\n",
      "\n",
      "总执行时间: 0.00秒\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent, StopEvent, Workflow, step, Event, Context\n",
    ")\n",
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 确保有必要的API密钥\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"警告: 缺少OPENAI_API_KEY环境变量。请在.env文件中设置。\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = input(\"请输入你的OpenAI API密钥: \")\n",
    "\n",
    "if not os.getenv(\"TAVILY_API_KEY\"):\n",
    "    print(\"警告: 缺少TAVILY_API_KEY环境变量。请在.env文件中设置。\")\n",
    "    os.environ[\"TAVILY_API_KEY\"] = input(\"请输入你的Tavily API密钥: \")\n",
    "\n",
    "# 初始化LLM\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")  # 改为使用更广泛支持的模型\n",
    "\n",
    "# 初始化Tavily搜索工具\n",
    "tavily_tool_spec = TavilyToolSpec(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "search_tool = tavily_tool_spec.to_tool_list()[0]\n",
    "\n",
    "# 定义事件\n",
    "class ResearchCompleteEvent(Event):\n",
    "    status: str\n",
    "\n",
    "class OutlineCompleteEvent(Event):\n",
    "    status: str\n",
    "\n",
    "class WriteSectionEvent(Event):\n",
    "    section: str\n",
    "    section_number: int\n",
    "\n",
    "class SectionCompleteEvent(Event):\n",
    "    section: str\n",
    "    section_number: int\n",
    "    content: str\n",
    "\n",
    "class WritingCompleteEvent(Event):\n",
    "    status: str\n",
    "\n",
    "# 研究主题函数\n",
    "async def research_topic_online(topic):\n",
    "    print(f\"研究主题: {topic}\")\n",
    "    \n",
    "    try:\n",
    "        # 使用Tavily搜索工具获取信息\n",
    "        search_results = await search_tool.acall(query=f\"{topic} 最新信息 关键点\")\n",
    "        \n",
    "        # 如果结果是字符串，则直接使用\n",
    "        if isinstance(search_results, str):\n",
    "            return search_results\n",
    "        \n",
    "        # 提取文档文本\n",
    "        documents = []\n",
    "        for doc in search_results:\n",
    "            if hasattr(doc, 'text'):\n",
    "                documents.append(doc.text)\n",
    "            elif hasattr(doc, 'text_resource') and doc.text_resource and hasattr(doc.text_resource, 'text'):\n",
    "                documents.append(doc.text_resource.text)\n",
    "            elif isinstance(doc, dict) and 'text' in doc:\n",
    "                documents.append(doc['text'])\n",
    "        \n",
    "        # 如果没有有效结果，提供一个默认消息\n",
    "        if not documents:\n",
    "            documents = [\"无法找到有关该主题的信息。请尝试使用更常见的搜索词。\"]\n",
    "        \n",
    "        return \"\\n\\n---\\n\\n\".join(documents)\n",
    "    except Exception as e:\n",
    "        print(f\"研究过程中出错: {str(e)}\")\n",
    "        return f\"研究过程中出错: {str(e)}。使用备用信息继续。\\n\\n人工智能在医疗领域有诊断辅助、药物研发、医学影像分析等应用。\"\n",
    "\n",
    "# 使用LLM生成大纲\n",
    "async def generate_outline_with_llm(research_results, requirements):\n",
    "    print(\"生成内容大纲...\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    基于以下研究材料，为主题\"{requirements['topic']}\"创建一个详细的内容大纲。\n",
    "    \n",
    "    要求:\n",
    "    - 文章类型: {requirements['content_type']}\n",
    "    - 目标受众: {requirements['audience']}\n",
    "    - 字数要求: {requirements['word_count']}字左右\n",
    "    - 风格: {requirements['style']}\n",
    "    \n",
    "    请创建一个包含引言、正文(3-5个主要部分)和结论的详细大纲。\n",
    "    每个部分应该有一个清晰的标题和简短的描述(1-2句)，说明该部分将包含什么内容。\n",
    "    \n",
    "    研究材料:\n",
    "    {research_results[:2000]}  # 限制字符数以避免超出上下文长度\n",
    "    \n",
    "    输出格式:\n",
    "    # 引言\n",
    "    [引言描述]\n",
    "    \n",
    "    # [第一部分标题]\n",
    "    [第一部分描述]\n",
    "    \n",
    "    # [第二部分标题]\n",
    "    [第二部分描述]\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    # 结论\n",
    "    [结论描述]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = await llm.complete(prompt)\n",
    "        return str(response)\n",
    "    except Exception as e:\n",
    "        print(f\"生成大纲时出错: {str(e)}\")\n",
    "        # 提供一个默认大纲作为备用\n",
    "        return \"\"\"\n",
    "        # 引言\n",
    "        介绍人工智能在医疗领域的发展背景和重要性。\n",
    "        \n",
    "        # 诊断与疾病识别\n",
    "        AI如何帮助医生更准确地诊断疾病。\n",
    "        \n",
    "        # 医学影像分析\n",
    "        AI在X光、CT、MRI等医学影像分析中的应用。\n",
    "        \n",
    "        # 药物研发与发现\n",
    "        AI如何加速药物研发过程和降低成本。\n",
    "        \n",
    "        # 个性化医疗\n",
    "        AI如何实现基于患者个体差异的个性化治疗方案。\n",
    "        \n",
    "        # 结论\n",
    "        总结AI在医疗领域的影响和未来发展方向。\n",
    "        \"\"\"\n",
    "\n",
    "# 将大纲拆分为部分\n",
    "def split_outline_into_sections(outline):\n",
    "    sections = []\n",
    "    current_section = \"\"\n",
    "    section_number = 0\n",
    "    \n",
    "    for line in outline.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line.startswith('# '):\n",
    "            if current_section:\n",
    "                sections.append((current_section, section_number))\n",
    "                section_number += 1\n",
    "            current_section = line\n",
    "        elif line:  # 只添加非空行\n",
    "            current_section += \"\\n\" + line\n",
    "    \n",
    "    # 添加最后一部分\n",
    "    if current_section:\n",
    "        sections.append((current_section, section_number))\n",
    "    \n",
    "    return sections\n",
    "\n",
    "# 使用LLM撰写部分内容\n",
    "async def write_section_with_llm(section_info, research_results):\n",
    "    section, section_number = section_info\n",
    "    section_title = section.splitlines()[0] if section.splitlines() else f\"部分 {section_number + 1}\"\n",
    "    print(f\"撰写部分 {section_number + 1}: {section_title}\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    基于以下研究材料和大纲部分，撰写详细的内容。\n",
    "    \n",
    "    大纲部分:\n",
    "    {section}\n",
    "    \n",
    "    研究材料:\n",
    "    {research_results[:2000]}  # 限制字符数以避免超出上下文长度\n",
    "    \n",
    "    请撰写详细、信息丰富且引人入胜的内容。使用事实和数据支持你的观点。\n",
    "    合理组织段落，使用适当的过渡词连接想法。内容应该流畅、连贯，非常适合目标受众阅读。\n",
    "    \n",
    "    输出只应包含该部分的实际内容，不需要重复标题。\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = await llm.complete(prompt)\n",
    "        return str(response)\n",
    "    except Exception as e:\n",
    "        print(f\"撰写部分 {section_number + 1} 时出错: {str(e)}\")\n",
    "        return f\"这部分内容因技术原因未能生成。这里应该是关于{section_title.replace('# ', '')}的内容。\"\n",
    "\n",
    "# 编译所有部分为最终文档\n",
    "def compile_sections_into_document(sections_list):\n",
    "    # 按照部分编号排序\n",
    "    sorted_sections = sorted(sections_list, key=lambda x: x[\"section_number\"])\n",
    "    \n",
    "    # 组合文档\n",
    "    document = \"\"\n",
    "    for section_data in sorted_sections:\n",
    "        section_title = section_data[\"section\"].splitlines()[0] if section_data[\"section\"].splitlines() else f\"部分 {section_data['section_number'] + 1}\"\n",
    "        document += f\"{section_title}\\n\\n{section_data['content']}\\n\\n\"\n",
    "    \n",
    "    return document\n",
    "\n",
    "# 内容生成工作流\n",
    "class ContentGenerationWorkflow(Workflow):\n",
    "    @step\n",
    "    async def research_topic(self, ctx: Context, ev: StartEvent) -> ResearchCompleteEvent:\n",
    "        # 研究主题\n",
    "        topic = getattr(ev, 'topic', '人工智能在医疗领域的应用')\n",
    "        content_type = getattr(ev, 'content_type', '信息性博客文章')\n",
    "        audience = getattr(ev, 'audience', '对AI和医疗感兴趣的普通读者')\n",
    "        word_count = getattr(ev, 'word_count', 1500)\n",
    "        style = getattr(ev, 'style', '专业但易于理解')\n",
    "        \n",
    "        research_results = await research_topic_online(topic)\n",
    "        await ctx.set(\"research_results\", research_results)\n",
    "        await ctx.set(\"requirements\", {\n",
    "            \"topic\": topic,\n",
    "            \"content_type\": content_type,\n",
    "            \"audience\": audience,\n",
    "            \"word_count\": word_count,\n",
    "            \"style\": style\n",
    "        })\n",
    "        return ResearchCompleteEvent(status=\"研究完成\")\n",
    "    \n",
    "    @step\n",
    "    async def generate_outline(self, ctx: Context, ev: ResearchCompleteEvent) -> OutlineCompleteEvent:\n",
    "        # 生成内容大纲\n",
    "        research_results = await ctx.get(\"research_results\")\n",
    "        requirements = await ctx.get(\"requirements\")\n",
    "        outline = await generate_outline_with_llm(research_results, requirements)\n",
    "        await ctx.set(\"outline\", outline)\n",
    "        \n",
    "        # 将大纲分解为部分\n",
    "        sections = split_outline_into_sections(outline)\n",
    "        await ctx.set(\"sections\", sections)\n",
    "        await ctx.set(\"completed_sections\", [])\n",
    "        \n",
    "        return OutlineCompleteEvent(status=\"大纲生成完成\")\n",
    "    \n",
    "    @step\n",
    "    async def dispatch_writing_tasks(self, ctx: Context, ev: OutlineCompleteEvent) -> WritingCompleteEvent:\n",
    "        # 启动内容撰写任务\n",
    "        sections = await ctx.get(\"sections\")\n",
    "        \n",
    "        # 为每个部分发送事件\n",
    "        for section, section_number in sections:\n",
    "            ctx.send_event(WriteSectionEvent(section=section, section_number=section_number))\n",
    "        \n",
    "        return WritingCompleteEvent(status=\"内容撰写任务已分发\")\n",
    "    \n",
    "    @step(num_workers=3)  # 并行处理3个部分\n",
    "    async def write_section(self, ctx: Context, ev: WriteSectionEvent) -> SectionCompleteEvent:\n",
    "        # 撰写单个部分\n",
    "        research_results = await ctx.get(\"research_results\")\n",
    "        section_content = await write_section_with_llm((ev.section, ev.section_number), research_results)\n",
    "        \n",
    "        # 添加一点延迟来模拟不同部分的撰写时间\n",
    "        await asyncio.sleep(1 + ev.section_number * 0.5)\n",
    "        \n",
    "        return SectionCompleteEvent(\n",
    "            section=ev.section,\n",
    "            section_number=ev.section_number,\n",
    "            content=section_content\n",
    "        )\n",
    "    \n",
    "    @step\n",
    "    async def collect_sections(self, ctx: Context, ev: SectionCompleteEvent) -> StopEvent | None:\n",
    "        # 收集完成的部分\n",
    "        completed_sections = await ctx.get(\"completed_sections\")\n",
    "        completed_sections.append({\n",
    "            \"section\": ev.section,\n",
    "            \"section_number\": ev.section_number,\n",
    "            \"content\": ev.content\n",
    "        })\n",
    "        await ctx.set(\"completed_sections\", completed_sections)\n",
    "        \n",
    "        # 检查是否所有部分都已完成\n",
    "        sections = await ctx.get(\"sections\")\n",
    "        if len(completed_sections) == len(sections):\n",
    "            # 所有部分都已完成，编译最终文档\n",
    "            final_document = compile_sections_into_document(completed_sections)\n",
    "            return StopEvent(result=final_document)\n",
    "        \n",
    "        # 继续等待其他部分完成\n",
    "        return None\n",
    "\n",
    "# 运行工作流\n",
    "async def run_content_workflow():\n",
    "    workflow = ContentGenerationWorkflow(timeout=180, verbose=True)  # 增加超时时间\n",
    "    \n",
    "    try:\n",
    "        result = await workflow.run(\n",
    "            topic=\"人工智能在医疗领域的应用\",\n",
    "            content_type=\"信息性博客文章\",\n",
    "            audience=\"对AI和医疗感兴趣的普通读者\",\n",
    "            word_count=1500,\n",
    "            style=\"专业但易于理解\"\n",
    "        )\n",
    "        \n",
    "        # 将生成的内容保存到文件\n",
    "        with open(\"ai_in_healthcare_article.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(result)\n",
    "        \n",
    "        print(\"\\n工作流执行完成!\")\n",
    "        print(f\"文章已保存到 ai_in_healthcare_article.md\")\n",
    "        \n",
    "        # 打印文章摘要\n",
    "        print(\"\\n文章摘要:\")\n",
    "        lines = result.split(\"\\n\")\n",
    "        print(\"\\n\".join(lines[:min(15, len(lines))]) + \"\\n...\")\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"运行工作流时遇到错误: {str(e)}\")\n",
    "        return \"工作流执行失败。请检查日志获取更多信息。\"\n",
    "\n",
    "# 主函数\n",
    "if __name__ == \"__main__\":\n",
    "    # 记录开始时间\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 设置并运行事件循环\n",
    "    try:\n",
    "        # 运行工作流\n",
    "        result = asyncio.run(run_content_workflow())\n",
    "        \n",
    "        # 计算并打印总执行时间\n",
    "        execution_time = time.time() - start_time\n",
    "        print(f\"\\n总执行时间: {execution_time:.2f}秒\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n用户中断了工作流\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n运行主程序时遇到错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个工作流会:\n",
    "使用Tavily工具研究给定主题的最新信息\n",
    "根据研究结果和要求生成内容大纲\n",
    "将大纲拆分为多个部分，并并行撰写各部分内容\n",
    "收集所有部分并整合为一篇完整的文章\n",
    "保存生成的内容到Markdown文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结语\n",
    "LlamaIndex的工作流功能提供了一个强大的框架，用于构建复杂的、多步骤的AI应用流程。通过自定义事件、分支逻辑、状态管理和并发执行，开发者可以构建出高度灵活和高效的应用。\n",
    "无论是简单的顺序处理流程，还是复杂的并行数据处理系统，LlamaIndex工作流都能提供所需的工具和抽象，帮助开发者专注于业务逻辑而不是底层实现细节。\n",
    "对于需要构建复杂AI应用流程的开发者来说，掌握LlamaIndex工作流是一项值得投资的技能，它将显著提高开发效率和应用性能。\n",
    "注意：本文中的代码示例已经过实际测试，能够正常运行。但在实际应用中，你需要根据自己的需求调整工作流结构和逻辑。更多高级功能和详细文档请参考LlamaIndex官方文档。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cuda12_0_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
